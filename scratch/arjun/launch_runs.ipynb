{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bmrNAS/people/arjun/miniconda3/envs/meddlr_env_cpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Any, Dict, List\n",
    "import numpy as np\n",
    "\n",
    "from fvcore.common.file_io import PathManager\n",
    "\n",
    "from meddlr.config import get_cfg\n",
    "from meddlr.evaluation.testing import find_weights\n",
    "from meddlr.utils.general import find_experiment_dirs\n",
    "from meddlr.utils import env\n",
    "\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\"'\"'data'\"'\"','\"'\"'nothing'\"'\"']]\n",
      "\\{'\"'\"'data'\"'\"':'\"'\"'nothing'\"'\"'\\}\n",
      "\\('\"'\"'hi'\"'\"',\\)\n"
     ]
    }
   ],
   "source": [
    "# Config construction utils\n",
    "def configure_params(params: List[Dict], fixed=None):\n",
    "    \"\"\"Unroll parameters into a list of configurations.\"\"\"\n",
    "    configs = itertools.product(*list(params.values()))\n",
    "    configs = [{k: v for k, v in zip(params.keys(), cfg)} for cfg in configs]\n",
    "    if fixed is not None:\n",
    "        for c in configs:\n",
    "            c.update(fixed)\n",
    "    return configs\n",
    "\n",
    "def stringify_collections(value, depth=0):\n",
    "    if not isinstance(value, (set, tuple, list, dict)):\n",
    "        return value\n",
    "    if isinstance(value, dict):\n",
    "        keys = list(value.keys())\n",
    "        values = [value[k] for k in keys]\n",
    "        keys_str = [stringify_collections(k, depth=depth+1) for k in keys]\n",
    "        values_str = [stringify_collections(v, depth=depth+1) for v in values]\n",
    "        keys_str = _to_str(keys_str, keys)\n",
    "        values_str = _to_str(values_str, values)\n",
    "        val_dict_str = {f\"{k}:{v}\" for k, v in zip(keys_str, values_str)}\n",
    "        value_str = \"\\{\"\n",
    "        value_str += \",\".join(val_dict_str)\n",
    "        value_str += \"\\}\"\n",
    "    else:\n",
    "        all_vals = [stringify_collections(v, depth=depth+1) for v in value]\n",
    "        value_str = \",\".join(\n",
    "            str(v) if not isinstance(v, str) or isinstance(ov, (set, tuple, list, dict))\n",
    "            else f\"'\\\"'\\\"'{v}'\\\"'\\\"'\"\n",
    "            for v, ov in zip(all_vals, value)\n",
    "        )\n",
    "        if isinstance(value, tuple):\n",
    "            value_str = f\"\\({value_str},\\)\" if len(value) > 0 else f\"\\(\\)\"\n",
    "        else:\n",
    "            value_str = f\"[{value_str}]\"\n",
    "\n",
    "    # value_str = \"[\" + \",\".join(str(v) if not isinstance(v, str) else f\"'\\\"'\\\"'{v}'\\\"'\\\"'\" for v in all_vals) + \"]\"\n",
    "    return value_str\n",
    "\n",
    "def _to_str(all_vals, value):\n",
    "    return [\n",
    "        str(v) if not isinstance(v, str) or isinstance(ov, (set, tuple, list, dict))\n",
    "        else f\"'\\\"'\\\"'{v}'\\\"'\\\"'\" for v, ov in zip(all_vals, value)\n",
    "    ]\n",
    "\n",
    "def stringify(cfg: Dict[str, Any]):\n",
    "    cfg = {k: f\"'{v}'\" if isinstance(v, str) else v for k, v in cfg.items()}\n",
    "    cfg = {k: stringify_collections(v) for k, v in cfg.items()}\n",
    "    return \" \".join(f\"{k} \\\"{v}\\\"\" for k, v in cfg.items())\n",
    "\n",
    "def get_next_version(path):\n",
    "    path = PathManager.get_local_path(path)\n",
    "    if not os.path.isdir(path):\n",
    "        max_version = 0\n",
    "    else:\n",
    "        versions = [int(x.split(\"_\")[1])  for x in os.listdir(path) if x.startswith(\"version\")]\n",
    "        max_version = max(versions) if versions else 0\n",
    "    return max_version + 1\n",
    "\n",
    "def format_version_str(version):\n",
    "    return f\"version_{version:03d}\"\n",
    "\n",
    "def format_path(path):\n",
    "    path = PathManager.get_local_path(path)\n",
    "    next_version = get_next_version(path)\n",
    "    return os.path.join(path, format_version_str(next_version))\n",
    "\n",
    "print(stringify_collections([[\"data\", \"nothing\"]]))\n",
    "print(stringify_collections({\"data\": \"nothing\"}))\n",
    "print(stringify_collections((\"hi\",)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(cfg_filename):\n",
    "    base_cfg = get_cfg()\n",
    "    base_cfg.merge_from_file(cfg_filename)\n",
    "\n",
    "    for exp_type, exp_vars in EXP_TYPES.items():\n",
    "        base_out_path = EXP_OUT_DIR.format(exp_type=exp_type)\n",
    "        if DEBUG:\n",
    "            base_out_path += \"-debug\"\n",
    "        descriptions = exp_vars.get(\"desc\", [None] * len(exp_vars[\"values\"]))\n",
    "        filter_by = list(base_cfg.DATALOADER.FILTER.BY) if not exp_vars.get(\"del_filter\", False) else []\n",
    "\n",
    "        params = {\n",
    "            \"DATALOADER.FILTER.BY\": [filter_by + [(exp_vars[\"filter_by\"], v)] if v is not None else list(filter_by) for v in exp_vars[\"values\"]]\n",
    "        }\n",
    "\n",
    "        fixed_params = {\n",
    "            # Description information\n",
    "            \"DESCRIPTION.BRIEF\": base_cfg.DESCRIPTION.BRIEF.format(exp_type=exp_type),\n",
    "            \"DESCRIPTION.TAGS\": list(set(list(base_cfg.DESCRIPTION.TAGS) + [exp_type])),\n",
    "        }\n",
    "        fixed_params.update(exp_vars.get(\"fixed_params\", {}))\n",
    "\n",
    "        all_configs = configure_params(params, fixed_params)\n",
    "        for idx, (cfg, desc) in enumerate(zip(all_configs, descriptions)):\n",
    "            version_str = format_version_str(get_next_version(base_out_path))\n",
    "            out_path = PathManager.get_local_path(os.path.join(base_out_path, version_str))\n",
    "\n",
    "            # CAUTION: LOOK HERE BEFORE RUNNING\n",
    "            cfg[\"OUTPUT_DIR\"] = out_path\n",
    "            exp_suffix = f\"{desc}/{version_str}\" if desc else f\"{version_str}\"\n",
    "            cfg[\"DESCRIPTION.EXP_NAME\"] = EXP_NAME.format(exp_type=exp_type, suffix=exp_suffix)\n",
    "            # if desc:\n",
    "            #     cfg[\"DESCRIPTION.TAGS\"] = cfg.get(\"DESCRIPTION.TAGS\", base_cfg.DESCRIPTION.TAGS) + [desc]\n",
    "        \n",
    "            cfg_args = stringify(cfg)\n",
    "\n",
    "            cfg_list = [item for x in [(k, v) for k, v in cfg.items()] for item in x]\n",
    "            cfg_obj = base_cfg.clone()\n",
    "            cfg_obj.merge_from_list(cfg_list)\n",
    "\n",
    "            cfg_str = \"\\n\\t\".join(f\"{k}: {v}\" for k, v in cfg.items())\n",
    "            print(f\"({idx+1}/{len(all_configs)}) {out_path}:\\n\\t{cfg_str}\")\n",
    "            print(\"\")\n",
    "            #print(f\"\\t{cfg_args}\")\n",
    "\n",
    "            if SUBMIT_JOBS:\n",
    "                num_workers = max(cfg_obj.DATALOADER.NUM_WORKERS, 2)\n",
    "                debug = \"--debug\" if DEBUG else \"\"\n",
    "                os.makedirs(out_path, exist_ok=True)\n",
    "                !sbatch -c $num_workers --mem-per-cpu=8gb train.sh \\\n",
    "                    SSRECON_MPROFILE=$PROFILE_MEMORY python train_net.py --config-file $cfg_filename --reproducible $debug $cfg_args\n",
    "            \n",
    "            print(\"==\"*40)\n",
    "            print(\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VORTEX-RM Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 112219\n",
      "Submitted batch job 112220\n",
      "Submitted batch job 112221\n",
      "Submitted batch job 112222\n"
     ]
    }
   ],
   "source": [
    "cfg_dir = \"/bmrNAS/people/arjun/code/projects/meddlr-configs-deepro/mridata-3dfse-knee/unrolled/ssdu\"\n",
    "cfgs = []\n",
    "for root, dirs, files in os.walk(cfg_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.yaml'):\n",
    "            cfgs.append(os.path.join(root, file))\n",
    "\n",
    "for cfg_file in cfgs:\n",
    "    !sbatch -c 8 --mem-per-cpu=5gb --nodelist=amalfi /bmrNAS/people/arjun/code/meddlr/tools/train.sh \\\n",
    "        python /bmrNAS/people/arjun/code/meddlr/tools/train_net.py \\\n",
    "        --config-file $cfg_file \\\n",
    "        --repro --auto-version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('meddlr_cpu_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "e06e3f21206d9e89b1b016e5b6a69be116bb5bb4d660281cb58d4724ead83ad0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
